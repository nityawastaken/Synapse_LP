{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nityawastaken/Synapse_LP/blob/week-8/nitya_task_8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **NLP Task 3**\n",
        "\n",
        "## **DJS Synapse Learning Period**\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "ewWyhbXsfU-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hello Everyone. Hope you learn and have fun throughout the task!\n",
        "\n",
        "Now, that we have understood how RNN works, let's dive deeper into LSTM and implement it from scratch."
      ],
      "metadata": {
        "id": "IRKiFuZIPFbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Refer to the material linked below to understand LSTM in detail.\n",
        "\n",
        "https://weberna.github.io/blog/2017/11/15/LSTM-Vanishing-Gradients.html\n",
        "\n",
        "https://medium.com/@chunduri11/understanding-lstm-plain-and-simple-96026b4468c6\n",
        "\n",
        "https://www.youtube.com/watch?v=YCzL96nL7j0&t=1009s&pp=ygUObHN0bSBzdGF0cXVlc3Q%3D\n",
        "\n",
        "https://medium.com/analytics-vidhya/introduction-to-long-short-term-memory-lstm-a8052cd0d4cd\n",
        "\n",
        "https://medium.com/@anishnama20/understanding-lstm-architecture-pros-and-cons-and-implementation-3e0cca194094"
      ],
      "metadata": {
        "id": "82sBtTYHZStd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and preprocess the data."
      ],
      "metadata": {
        "id": "2nrh2F2xdD7q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPWQiZXPOlQ8"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Data #####\n",
        "data = \"\"\"To be, or not to be, that is the question: Whether \\\n",
        "'tis nobler in the mind to suffer The slings and arrows of ou\\\n",
        "trageous fortune, Or to take arms against a sea of troubles A\\\n",
        "nd by opposing end them. To die—to sleep, No more; and by a s\\\n",
        "leep to say we end The heart-ache and the thousand natural sh\\\n",
        "ocks That flesh is heir to: 'tis a consummation Devoutly to b\\\n",
        "e wish'd. To die, to sleep; To sleep, perchance to dream—ay, \\\n",
        "there's the rub: For in that sleep of death what dreams may c\\\n",
        "ome, When we have shuffled off this mortal coil, Must give us\\\n",
        " pause—there's the respect That makes calamity of so long lif\\\n",
        "e. For who would bear the whips and scorns of time, Th'oppres\\\n",
        "sor's wrong, the proud man's contumely, The pangs of dispriz'\\\n",
        "d love, the law's delay, The insolence of office, and the spu\\\n",
        "rns That patient merit of th'unworthy takes, When he himself \\\n",
        "might his quietus make\"\"\".lower()"
      ],
      "metadata": {
        "id": "jNLoQ5IZQRuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = set(data)\n",
        "data_size, char_size = len(data), len(chars)"
      ],
      "metadata": {
        "id": "Mbp2ZtAzQl6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Data size: {data_size}, Char Size: {char_size}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osolnymQQutt",
        "outputId": "d27ca399-8572-4c8f-9b4e-470494c9cbc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data size: 866, Char Size: 32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char_to_idx = {c:i for i, c in enumerate(chars)}\n",
        "idx_to_char = {i:c for i, c in enumerate(chars)}"
      ],
      "metadata": {
        "id": "FF8l2QQTQw1q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform train test split"
      ],
      "metadata": {
        "id": "XpudyNBBQ0UP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#perform train test split here\n",
        "\n",
        "sequence_length = 32\n",
        "inputs = []\n",
        "targets = []\n",
        "for i in range(0, len(data) - sequence_length, 1):\n",
        "    inputs.append(data[i:i + sequence_length])\n",
        "    targets.append(data[i + sequence_length])\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "gqIB6IV8Qz12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define onHotEncoding Function"
      ],
      "metadata": {
        "id": "wSfGCQ1bh9Vl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Helper Functions #####\n",
        "def oneHotEncode(text):\n",
        "    output = np.zeros((char_size, 1))\n",
        "    output[char_to_idx[text]] = 1\n",
        "\n",
        "    return output"
      ],
      "metadata": {
        "id": "fBv9U8Q9RADr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read about Xavier Initialization.\n",
        "\n",
        "https://cs230.stanford.edu/section/4/"
      ],
      "metadata": {
        "id": "6Wn2OpJQcmLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Xavier Normalized Initialization\n",
        "def initWeights(input_size, output_size):\n",
        "    return np.random.uniform(-1, 1, (output_size, input_size)) * np.sqrt(6 / (input_size + output_size))"
      ],
      "metadata": {
        "id": "lngBGI2_REac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Activation Functions required."
      ],
      "metadata": {
        "id": "mLCH8CY3cv9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(input, derivative = False):\n",
        "    if derivative:\n",
        "        return input * (1 - input)\n",
        "\n",
        "    return 1 / (1 + np.exp(-input))"
      ],
      "metadata": {
        "id": "OjjUtx_HRJjS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#similarly define tanh activation function here.\n",
        "def tanh(input, derivative = False):\n",
        "    if derivative:\n",
        "        return 1 - input ** 2\n",
        "\n",
        "    return np.tanh(input)"
      ],
      "metadata": {
        "id": "riH1tRNIRSTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax(input):\n",
        "    return np.exp(input) / np.sum(np.exp(input))"
      ],
      "metadata": {
        "id": "vfQU50nURT8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's implement LSTM from scratch!"
      ],
      "metadata": {
        "id": "JxFTxsI5dJoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### Long Short-Term Memory Network Class #####\n",
        "class LSTM:\n",
        "    def __init__(self, input_size, hidden_size, output_size, num_epochs, learning_rate):\n",
        "        # Hyperparameters\n",
        "        self.learning_rate = learning_rate\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_epochs = num_epochs\n",
        "\n",
        "        # Forget Gate\n",
        "        self.wf = initWeights(input_size, hidden_size)\n",
        "        self.bf = np.zeros((hidden_size, 1))\n",
        "\n",
        "        # Input Gate\n",
        "        self.wi = initWeights(input_size, hidden_size) ##\n",
        "        self.bi = np.zeros((hidden_size, 1)) ##\n",
        "\n",
        "        # Cell states update weights\n",
        "        self.wc = initWeights(input_size, hidden_size)\n",
        "        self.bc = np.zeros((hidden_size, 1))\n",
        "\n",
        "        # Output Gate\n",
        "        self.wo = initWeights(input_size, hidden_size)\n",
        "        self.bo = np.zeros((hidden_size, 1))\n",
        "\n",
        "        # Final output weights\n",
        "        self.wy = initWeights(hidden_size, output_size) ##\n",
        "        self.by = np.zeros((output_size, 1)) ##\n",
        "\n",
        "     # Reset Network Memory\n",
        "    def reset(self):\n",
        "        self.concat_inputs = {}\n",
        "\n",
        "        self.hidden_states = {-1:np.zeros((self.hidden_size, 1))}\n",
        "        self.cell_states = {-1:np.zeros((self.hidden_size, 1))} ##\n",
        "\n",
        "        self.activation_outputs = {}\n",
        "        self.cell_updates = {}\n",
        "        self.output_gates = {}\n",
        "        self.forget_gates = {}\n",
        "        self.input_gates = {}\n",
        "        self.outputs = {}\n",
        "\n",
        "    # Forward Propogation\n",
        "    def forward(self, inputs):\n",
        "        self.reset()\n",
        "\n",
        "        outputs = []\n",
        "        for q in range(len(inputs)):\n",
        "            self.concat_inputs[q] = np.concatenate((self.hidden_states[q - 1], inputs[q]))\n",
        "\n",
        "            self.forget_gates[q] = sigmoid(np.dot(self.wf, self.concat_inputs[q]) + self.bf)\n",
        "            self.input_gates[q] = sigmoid(np.dot(self.wi, self.concat_inputs[q]) + self.bi)\n",
        "            self.cell_updates[q] =  tanh(np.dot(self.wc, self.concat_inputs[q]) + self.bc) ##\n",
        "            self.output_gates[q] = sigmoid(np.dot(self.wo, self.concat_inputs[q]) + self.bo) ##\n",
        "\n",
        "            self.cell_states[q] = self.forget_gates[q] * self.cell_states[q - 1] + self.input_gates[q] * self.cell_updates[q]\n",
        "            self.hidden_states[q] = self.output_gates[q] * tanh(self.cell_states[q])\n",
        "\n",
        "            outputs += [np.dot(self.wy, self.hidden_states[q]) + self.by]\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    # Backward Propogation\n",
        "    def backward(self, errors, inputs):\n",
        "        d_wf, d_bf = np.zeros_like(self.wf), np.zeros_like(self.bf) ##\n",
        "        d_wi, d_bi = np.zeros_like(self.wi), np.zeros_like(self.bi) ##\n",
        "        d_wc, d_bc = np.zeros_like(self.wc), np.zeros_like(self.bc) ##\n",
        "        d_wo, d_bo = np.zeros_like(self.wo), np.zeros_like(self.bo) ##\n",
        "        d_wy, d_by = np.zeros_like(self.wy), np.zeros_like(self.by) ##\n",
        "\n",
        "        dh_next, dc_next = np.zeros_like(self.hidden_states[0]), np.zeros_like(self.cell_states[0])\n",
        "        for q in reversed(range(len(inputs))):\n",
        "            error = errors[q]\n",
        "\n",
        "            # Final Gate Weights and Biases Errors\n",
        "            d_wy += np.dot(error, self.hidden_states[q].T)\n",
        "            d_by += error\n",
        "\n",
        "            # Hidden State Error\n",
        "            d_hs = np.dot(self.wy.T, error) + dh_next\n",
        "\n",
        "            # Output Gate Weights and Biases Errors\n",
        "            d_o = tanh(self.cell_states[q]) * d_hs * sigmoid(self.output_gates[q], derivative = True)\n",
        "            d_wo += np.dot(d_o, inputs[q].T)\n",
        "            d_bo += d_o\n",
        "\n",
        "            # Cell State Error\n",
        "            d_cs = tanh(tanh(self.cell_states[q]), derivative = True) * self.output_gates[q] * d_hs + dc_next\n",
        "\n",
        "            # Forget Gate Weights and Biases Errors\n",
        "            d_f = d_cs * self.cell_states[q - 1] * sigmoid(self.forget_gates[q], derivative = True)\n",
        "            d_wf += np.dot(d_f, inputs[q].T)\n",
        "            d_bf += d_f\n",
        "\n",
        "            # Input Gate Weights and Biases Errors\n",
        "            #fill this (take forget gate weights and biases errors as reference)\n",
        "            d_i = d_cs * self.input_gates[q] * sigmoid(self.input_gates[q], derivative = True)\n",
        "            d_wi += np.dot(d_i, inputs[q].T)\n",
        "            d_bi += d_i\n",
        "\n",
        "            # Cell update weights and errors\n",
        "            d_c = d_cs * self.input_gates[q] * tanh(self.cell_updates[q], derivative = True)\n",
        "            d_wc += np.dot(d_c, inputs[q].T)\n",
        "            d_bc += d_c\n",
        "\n",
        "            # Concatenated Input Error (Sum of Error at Each Gate!)\n",
        "            d_z = np.dot(self.wf.T, d_f) + np.dot(self.wi.T, d_i) + np.dot(self.wc.T, d_c) + np.dot(self.wo.T, d_o)\n",
        "\n",
        "            # Error of Hidden State and Cell State at Next Time Step\n",
        "            dh_next = d_z[:self.hidden_size, :]\n",
        "            dc_next = self.forget_gates[q] * d_cs\n",
        "\n",
        "        for d_ in (d_wf, d_bf, d_wi, d_bi, d_wc, d_bc, d_wo, d_bo, d_wy, d_by):\n",
        "            np.clip(d_, -1, 1, out = d_)\n",
        "\n",
        "        self.wf += d_wf * self.learning_rate\n",
        "        self.bf += d_bf * self.learning_rate\n",
        "\n",
        "        self.wi += d_wi * self.learning_rate ##\n",
        "        self.bi += d_bi * self.learning_rate ##\n",
        "\n",
        "        self.wc += d_wc * self.learning_rate\n",
        "        self.bc += d_bc * self.learning_rate\n",
        "\n",
        "        self.wo += d_wo * self.learning_rate ##\n",
        "        self.bo += d_bo * self.learning_rate ##\n",
        "\n",
        "        self.wy += d_wy * self.learning_rate\n",
        "        self.by += d_by * self.learning_rate\n",
        "\n",
        "\n",
        "    # Train\n",
        "    def train(self, inputs, labels):\n",
        "        inputs = [oneHotEncode(input).reshape(1, -1) for input in inputs]\n",
        "\n",
        "        for _ in tqdm(range(self.num_epochs)):\n",
        "            predictions = self.forward(inputs)\n",
        "\n",
        "            errors = []\n",
        "            for q in range(len(predictions)):\n",
        "                errors += [-softmax(predictions[q])]\n",
        "                errors[-1][char_to_idx[labels[q]]] += 1\n",
        "\n",
        "            self.backward(errors, self.concat_inputs)\n",
        "\n",
        " # Test\n",
        "    def test(self, inputs, labels):\n",
        "        accuracy = 0\n",
        "        probabilities = self.forward([oneHotEncode(input).reshape(1, -1) for input in inputs])\n",
        "\n",
        "        output = ''\n",
        "        for q in range(len(labels)):\n",
        "            prediction = idx_to_char[np.random.choice([*range(char_size)], p = softmax(probabilities[q].reshape(-1)))]\n",
        "\n",
        "            output += prediction\n",
        "\n",
        "            if prediction == labels[q]:\n",
        "                accuracy += 1\n",
        "\n",
        "        print(f'Ground Truth:\\nt{labels}\\n')\n",
        "        print(f'Predictions:\\nt{\"\".join(output)}\\n')\n",
        "        print(f'Accuracy: {round(accuracy * 100 / len(inputs), 2)}%')"
      ],
      "metadata": {
        "id": "iA23-hwGLFBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hope you understood the implementation! Explain what you understood in detail.\n",
        "\n",
        "Ans:"
      ],
      "metadata": {
        "id": "nVMss0aXFv7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Network\n",
        "hidden_size = 128 ##\n",
        "\n",
        "lstm = LSTM(input_size = char_size + hidden_size, hidden_size = hidden_size, output_size = char_size, num_epochs = 1_000, learning_rate = 0.05)\n",
        "\n",
        "##### Training #####\n",
        "lstm.train(X_train, y_train)\n",
        "\n",
        "##### Testing #####\n",
        "# write the code to test the model\n",
        "lstm.test(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "id": "loaXDn6ZRZsV",
        "outputId": "bbd3e4cd-c749-444a-d243-38cfbb5e21b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'ome, when we have shuffled off t'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7609c37dbdc5>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m##### Training #####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m##### Testing #####\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-5654c1f93ca0>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, inputs, labels)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moneHotEncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-5654c1f93ca0>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moneHotEncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minput\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-1d27bba8ef8f>\u001b[0m in \u001b[0;36moneHotEncode\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moneHotEncode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchar_to_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'ome, when we have shuffled off t'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Machine Translation using Encoder-Decoder**"
      ],
      "metadata": {
        "id": "YrbJvameYvG1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read about Encoder-Decoder in the links provided below\n",
        "\n",
        "https://www.youtube.com/watch?v=KiL74WsgxoA&t=292s&pp=ygUcZW5jb2RlciBkZWNvZGVyIGFyY2hpdGVjdHVyZQ%3D%3D\n",
        "\n",
        "https://www.youtube.com/watch?v=L8HKweZIOmg&pp=ygUcZW5jb2RlciBkZWNvZGVyIGFyY2hpdGVjdHVyZQ%3D%3D\n",
        "\n",
        "https://medium.com/analytics-vidhya/machine-translation-encoder-decoder-model-7e4867377161\n",
        "\n",
        "https://medium.com/@anishnama20/exploring-the-power-of-encoder-decoder-models-pros-cons-and-applications-8bfbe2e66e76"
      ],
      "metadata": {
        "id": "ssYSOjf2d3p9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import re\n",
        "from numpy import array, argmax, random, take\n",
        "import pandas as pd\n",
        "import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "UIP5GhwuYdSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the dataset provided with the task for this implementation."
      ],
      "metadata": {
        "id": "TV-uCuQAGrpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "95o-IKgTcUkW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba753ce2-dd8b-43c3-8a3b-6d7c0fa879d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"/content/drive/MyDrive/synapse/week 8 dataset.txt\""
      ],
      "metadata": {
        "id": "-4dx6yqoRii_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_samples = 10000"
      ],
      "metadata": {
        "id": "WDTBobqLcalN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "    # We use \"tab\" as the \"start sequence\" character\n",
        "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "    target_text = \"\\t\" + target_text + \"\\n\" ##\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "    for char in input_text:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "    #similarly write the code for target_text\n",
        "    for char in target_text: ##\n",
        "        if char not in target_characters: ##\n",
        "            target_characters.add(char) ##"
      ],
      "metadata": {
        "id": "1IxkMb-dY9rH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters)) ##\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters) ##\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts]) ##"
      ],
      "metadata": {
        "id": "elGq7s2oZA-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ],
      "metadata": {
        "id": "oU2UxNPgZI-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "537020ed-3b76-436a-c301-e55d4a7ba704"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 10000\n",
            "Number of unique input tokens: 70\n",
            "Number of unique output tokens: 91\n",
            "Max sequence length for inputs: 14\n",
            "Max sequence length for outputs: 59\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)]) ##"
      ],
      "metadata": {
        "id": "clzOI8YNclEi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ") ##!!!!\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
        "    dtype=\"float32\",\n",
        ")"
      ],
      "metadata": {
        "id": "_oIqWl1gcn2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ],
      "metadata": {
        "id": "Yk3hmkOLcwgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space"
      ],
      "metadata": {
        "id": "jD8Ng5D6dGr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)"
      ],
      "metadata": {
        "id": "vknpfCvNczP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c] ##"
      ],
      "metadata": {
        "id": "D_4xr5Y1dFEK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))"
      ],
      "metadata": {
        "id": "4WStsjhhdRFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs) ##"
      ],
      "metadata": {
        "id": "_4Y_enBydS2-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Define the model that will turn\n",
        " `encoder_input_data` & `decoder_input_data` into `decoder_target_data`"
      ],
      "metadata": {
        "id": "MJnvF6-xHEUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "metadata": {
        "id": "jIBkBoWAdVWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train the model\n",
        "model.compile(\n",
        "    #implement appropriate optimizer, loss and accuracy\n",
        "    optimizer=\"rmsprop\", ##\n",
        "    loss=\"categorical_crossentropy\", ##\n",
        "    metrics=[\"accuracy\"], ##\n",
        ")\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "# Save model\n",
        "model.save(\"model.keras\")"
      ],
      "metadata": {
        "id": "HbveFW4Okpsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "346e8451-e32e-431d-aa1f-0ed82098a60e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 16ms/step - accuracy: 0.7054 - loss: 1.5471 - val_accuracy: 0.7141 - val_loss: 1.3305\n",
            "Epoch 2/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7471 - loss: 0.9652 - val_accuracy: 0.7193 - val_loss: 0.9832\n",
            "Epoch 3/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7627 - loss: 0.8644 - val_accuracy: 0.7397 - val_loss: 0.8843\n",
            "Epoch 4/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.7836 - loss: 0.7765 - val_accuracy: 0.7714 - val_loss: 0.7989\n",
            "Epoch 5/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8030 - loss: 0.6880 - val_accuracy: 0.7882 - val_loss: 0.7328\n",
            "Epoch 6/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8153 - loss: 0.6413 - val_accuracy: 0.8023 - val_loss: 0.6932\n",
            "Epoch 7/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8219 - loss: 0.6140 - val_accuracy: 0.8078 - val_loss: 0.6615\n",
            "Epoch 8/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8290 - loss: 0.5826 - val_accuracy: 0.8109 - val_loss: 0.6417\n",
            "Epoch 9/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8324 - loss: 0.5688 - val_accuracy: 0.8218 - val_loss: 0.6174\n",
            "Epoch 10/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8385 - loss: 0.5498 - val_accuracy: 0.8255 - val_loss: 0.6030\n",
            "Epoch 11/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8438 - loss: 0.5320 - val_accuracy: 0.8301 - val_loss: 0.5903\n",
            "Epoch 12/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8495 - loss: 0.5143 - val_accuracy: 0.8337 - val_loss: 0.5782\n",
            "Epoch 13/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8544 - loss: 0.4973 - val_accuracy: 0.8357 - val_loss: 0.5632\n",
            "Epoch 14/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.8575 - loss: 0.4862 - val_accuracy: 0.8405 - val_loss: 0.5554\n",
            "Epoch 15/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8598 - loss: 0.4794 - val_accuracy: 0.8429 - val_loss: 0.5406\n",
            "Epoch 16/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.8638 - loss: 0.4632 - val_accuracy: 0.8456 - val_loss: 0.5303\n",
            "Epoch 17/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.8668 - loss: 0.4540 - val_accuracy: 0.8476 - val_loss: 0.5276\n",
            "Epoch 18/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8688 - loss: 0.4476 - val_accuracy: 0.8485 - val_loss: 0.5189\n",
            "Epoch 19/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8721 - loss: 0.4335 - val_accuracy: 0.8506 - val_loss: 0.5113\n",
            "Epoch 20/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8743 - loss: 0.4243 - val_accuracy: 0.8521 - val_loss: 0.5049\n",
            "Epoch 21/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8752 - loss: 0.4215 - val_accuracy: 0.8528 - val_loss: 0.5012\n",
            "Epoch 22/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8783 - loss: 0.4113 - val_accuracy: 0.8547 - val_loss: 0.4952\n",
            "Epoch 23/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8792 - loss: 0.4061 - val_accuracy: 0.8569 - val_loss: 0.4890\n",
            "Epoch 24/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.8815 - loss: 0.3991 - val_accuracy: 0.8577 - val_loss: 0.4854\n",
            "Epoch 25/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8828 - loss: 0.3924 - val_accuracy: 0.8590 - val_loss: 0.4793\n",
            "Epoch 26/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8858 - loss: 0.3842 - val_accuracy: 0.8598 - val_loss: 0.4789\n",
            "Epoch 27/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8873 - loss: 0.3785 - val_accuracy: 0.8612 - val_loss: 0.4717\n",
            "Epoch 28/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8870 - loss: 0.3783 - val_accuracy: 0.8611 - val_loss: 0.4731\n",
            "Epoch 29/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8906 - loss: 0.3668 - val_accuracy: 0.8633 - val_loss: 0.4646\n",
            "Epoch 30/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8926 - loss: 0.3598 - val_accuracy: 0.8635 - val_loss: 0.4640\n",
            "Epoch 31/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.8938 - loss: 0.3564 - val_accuracy: 0.8662 - val_loss: 0.4586\n",
            "Epoch 32/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8943 - loss: 0.3524 - val_accuracy: 0.8656 - val_loss: 0.4583\n",
            "Epoch 33/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.8969 - loss: 0.3455 - val_accuracy: 0.8661 - val_loss: 0.4582\n",
            "Epoch 34/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.8982 - loss: 0.3412 - val_accuracy: 0.8680 - val_loss: 0.4543\n",
            "Epoch 35/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9001 - loss: 0.3344 - val_accuracy: 0.8666 - val_loss: 0.4565\n",
            "Epoch 36/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9009 - loss: 0.3314 - val_accuracy: 0.8676 - val_loss: 0.4538\n",
            "Epoch 37/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9028 - loss: 0.3251 - val_accuracy: 0.8688 - val_loss: 0.4502\n",
            "Epoch 38/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9042 - loss: 0.3206 - val_accuracy: 0.8681 - val_loss: 0.4498\n",
            "Epoch 39/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9055 - loss: 0.3156 - val_accuracy: 0.8699 - val_loss: 0.4503\n",
            "Epoch 40/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9063 - loss: 0.3116 - val_accuracy: 0.8701 - val_loss: 0.4477\n",
            "Epoch 41/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9084 - loss: 0.3065 - val_accuracy: 0.8712 - val_loss: 0.4459\n",
            "Epoch 42/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9101 - loss: 0.3002 - val_accuracy: 0.8716 - val_loss: 0.4460\n",
            "Epoch 43/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9108 - loss: 0.2988 - val_accuracy: 0.8729 - val_loss: 0.4386\n",
            "Epoch 44/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 15ms/step - accuracy: 0.9124 - loss: 0.2925 - val_accuracy: 0.8716 - val_loss: 0.4444\n",
            "Epoch 45/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9144 - loss: 0.2878 - val_accuracy: 0.8723 - val_loss: 0.4430\n",
            "Epoch 46/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9138 - loss: 0.2855 - val_accuracy: 0.8741 - val_loss: 0.4395\n",
            "Epoch 47/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9152 - loss: 0.2833 - val_accuracy: 0.8732 - val_loss: 0.4443\n",
            "Epoch 48/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9166 - loss: 0.2775 - val_accuracy: 0.8748 - val_loss: 0.4410\n",
            "Epoch 49/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.9181 - loss: 0.2729 - val_accuracy: 0.8741 - val_loss: 0.4426\n",
            "Epoch 50/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9198 - loss: 0.2687 - val_accuracy: 0.8752 - val_loss: 0.4400\n",
            "Epoch 51/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9206 - loss: 0.2646 - val_accuracy: 0.8743 - val_loss: 0.4408\n",
            "Epoch 52/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9214 - loss: 0.2614 - val_accuracy: 0.8743 - val_loss: 0.4417\n",
            "Epoch 53/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9222 - loss: 0.2582 - val_accuracy: 0.8755 - val_loss: 0.4415\n",
            "Epoch 54/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9228 - loss: 0.2568 - val_accuracy: 0.8738 - val_loss: 0.4478\n",
            "Epoch 55/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9245 - loss: 0.2499 - val_accuracy: 0.8763 - val_loss: 0.4410\n",
            "Epoch 56/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9255 - loss: 0.2471 - val_accuracy: 0.8756 - val_loss: 0.4442\n",
            "Epoch 57/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9270 - loss: 0.2432 - val_accuracy: 0.8749 - val_loss: 0.4466\n",
            "Epoch 58/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9279 - loss: 0.2398 - val_accuracy: 0.8763 - val_loss: 0.4423\n",
            "Epoch 59/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9286 - loss: 0.2378 - val_accuracy: 0.8755 - val_loss: 0.4473\n",
            "Epoch 60/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9295 - loss: 0.2342 - val_accuracy: 0.8736 - val_loss: 0.4533\n",
            "Epoch 61/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9312 - loss: 0.2295 - val_accuracy: 0.8755 - val_loss: 0.4498\n",
            "Epoch 62/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.9310 - loss: 0.2284 - val_accuracy: 0.8754 - val_loss: 0.4548\n",
            "Epoch 63/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9321 - loss: 0.2265 - val_accuracy: 0.8759 - val_loss: 0.4493\n",
            "Epoch 64/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9330 - loss: 0.2210 - val_accuracy: 0.8761 - val_loss: 0.4510\n",
            "Epoch 65/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9343 - loss: 0.2183 - val_accuracy: 0.8762 - val_loss: 0.4561\n",
            "Epoch 66/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9352 - loss: 0.2144 - val_accuracy: 0.8736 - val_loss: 0.4607\n",
            "Epoch 67/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9365 - loss: 0.2111 - val_accuracy: 0.8746 - val_loss: 0.4569\n",
            "Epoch 68/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9367 - loss: 0.2101 - val_accuracy: 0.8750 - val_loss: 0.4611\n",
            "Epoch 69/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9381 - loss: 0.2061 - val_accuracy: 0.8752 - val_loss: 0.4633\n",
            "Epoch 70/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9384 - loss: 0.2042 - val_accuracy: 0.8759 - val_loss: 0.4616\n",
            "Epoch 71/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9391 - loss: 0.2018 - val_accuracy: 0.8751 - val_loss: 0.4648\n",
            "Epoch 72/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9401 - loss: 0.1980 - val_accuracy: 0.8757 - val_loss: 0.4645\n",
            "Epoch 73/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9411 - loss: 0.1961 - val_accuracy: 0.8760 - val_loss: 0.4648\n",
            "Epoch 74/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9422 - loss: 0.1931 - val_accuracy: 0.8758 - val_loss: 0.4690\n",
            "Epoch 75/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9427 - loss: 0.1900 - val_accuracy: 0.8764 - val_loss: 0.4694\n",
            "Epoch 76/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9437 - loss: 0.1873 - val_accuracy: 0.8756 - val_loss: 0.4748\n",
            "Epoch 77/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9441 - loss: 0.1854 - val_accuracy: 0.8750 - val_loss: 0.4756\n",
            "Epoch 78/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9455 - loss: 0.1822 - val_accuracy: 0.8743 - val_loss: 0.4794\n",
            "Epoch 79/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.9461 - loss: 0.1803 - val_accuracy: 0.8762 - val_loss: 0.4740\n",
            "Epoch 80/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9469 - loss: 0.1770 - val_accuracy: 0.8752 - val_loss: 0.4812\n",
            "Epoch 81/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9469 - loss: 0.1750 - val_accuracy: 0.8753 - val_loss: 0.4851\n",
            "Epoch 82/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9470 - loss: 0.1746 - val_accuracy: 0.8745 - val_loss: 0.4861\n",
            "Epoch 83/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9484 - loss: 0.1715 - val_accuracy: 0.8747 - val_loss: 0.4883\n",
            "Epoch 84/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9492 - loss: 0.1681 - val_accuracy: 0.8752 - val_loss: 0.4883\n",
            "Epoch 85/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.9504 - loss: 0.1647 - val_accuracy: 0.8747 - val_loss: 0.4935\n",
            "Epoch 86/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9507 - loss: 0.1635 - val_accuracy: 0.8755 - val_loss: 0.4957\n",
            "Epoch 87/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9515 - loss: 0.1603 - val_accuracy: 0.8751 - val_loss: 0.4997\n",
            "Epoch 88/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9522 - loss: 0.1583 - val_accuracy: 0.8755 - val_loss: 0.4991\n",
            "Epoch 89/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9529 - loss: 0.1561 - val_accuracy: 0.8730 - val_loss: 0.5059\n",
            "Epoch 90/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9530 - loss: 0.1551 - val_accuracy: 0.8738 - val_loss: 0.5068\n",
            "Epoch 91/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9530 - loss: 0.1561 - val_accuracy: 0.8737 - val_loss: 0.5116\n",
            "Epoch 92/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - accuracy: 0.9542 - loss: 0.1510 - val_accuracy: 0.8744 - val_loss: 0.5116\n",
            "Epoch 93/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9553 - loss: 0.1478 - val_accuracy: 0.8752 - val_loss: 0.5103\n",
            "Epoch 94/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9558 - loss: 0.1474 - val_accuracy: 0.8746 - val_loss: 0.5146\n",
            "Epoch 95/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9561 - loss: 0.1458 - val_accuracy: 0.8745 - val_loss: 0.5183\n",
            "Epoch 96/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9568 - loss: 0.1429 - val_accuracy: 0.8747 - val_loss: 0.5218\n",
            "Epoch 97/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9574 - loss: 0.1413 - val_accuracy: 0.8749 - val_loss: 0.5188\n",
            "Epoch 98/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - accuracy: 0.9583 - loss: 0.1380 - val_accuracy: 0.8744 - val_loss: 0.5243\n",
            "Epoch 99/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.9580 - loss: 0.1383 - val_accuracy: 0.8749 - val_loss: 0.5304\n",
            "Epoch 100/100\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9587 - loss: 0.1358 - val_accuracy: 0.8744 - val_loss: 0.5304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"model.keras\")"
      ],
      "metadata": {
        "id": "Fw5_xhyLksF8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder_inputs = model.input[0]\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)"
      ],
      "metadata": {
        "id": "LVxcRIDIB-Xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_inputs = model.input[1]\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,)) ##\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec] ##\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")"
      ],
      "metadata": {
        "id": "pM7-S9haCAF_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ],
      "metadata": {
        "id": "22ZnGf56CCDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the cell below and explain here in detail how the cell works."
      ],
      "metadata": {
        "id": "0fSQqeMZHuOi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict(\n",
        "            [target_seq] + states_value, verbose=0\n",
        "        )\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence"
      ],
      "metadata": {
        "id": "5oREePnkCEFk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for seq_index in range(20):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    print(\"-\")\n",
        "    print(\"Input sentence:\", input_texts[seq_index])\n",
        "    print(\"Decoded sentence:\", decoded_sentence)"
      ],
      "metadata": {
        "id": "k7DPkXy1CGiv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84d4265c-98f6-4dd9-8f04-b50fbfef278e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Continuez.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Continuez.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Continuez.\n",
            "\n",
            "-\n",
            "Input sentence: Go.\n",
            "Decoded sentence: Continuez.\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Hi.\n",
            "Decoded sentence: Salut !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run!\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n",
            "-\n",
            "Input sentence: Run.\n",
            "Decoded sentence: Fuyons !\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bonus Task**\n",
        "\n",
        "Exploring Bidirectional RNNs and the BiLSTM Architecture\n",
        "\n",
        "Implementing a BiLSTM model for a specific NLP task (e.g., named entity recognition or sentiment analysis)"
      ],
      "metadata": {
        "id": "j0YBdPGtgF1L"
      }
    }
  ]
}